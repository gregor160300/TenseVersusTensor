{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "956b92d3-6324-4076-bcd3-33aa1b3d32e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel, TextClassificationPipeline, Trainer, TrainingArguments\n",
    "import torch\n",
    "from datasets import load_dataset, concatenate_datasets, Dataset, ClassLabel\n",
    "import wandb\n",
    "import os\n",
    "import intel_extension_for_pytorch as ipex\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f64e595d-263c-484a-a59c-5316011c74af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of physical cores: 12\n",
      "Number of cores per socket: 6\n",
      "OpenMP environment variables:\n",
      "  - OMP_NUM_THREADS: 12\n",
      "  - OMP_PROC_BIND: close\n",
      "  - OMP_PLACES: cores\n"
     ]
    }
   ],
   "source": [
    "# This code snippet was taken from rahulunair/genAI, licensed under the Apache License 2.0.\n",
    "# Original source: https://github.com/rahulunair/genAI\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import psutil\n",
    "\n",
    "num_physical_cores = psutil.cpu_count(logical=False)\n",
    "num_cores_per_socket = num_physical_cores // 2\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"0\"\n",
    "#HF_TOKEN = os.environ[\"HF_TOKEN\"]\n",
    "\n",
    "# Set the LD_PRELOAD environment variable\n",
    "ld_preload = os.environ.get(\"LD_PRELOAD\", \"\")\n",
    "# conda_prefix = os.environ.get(\"CONDA_PREFIX\", \"\")\n",
    "# Improve memory allocation performance, if tcmalloc is not available, please comment this line out\n",
    "# os.environ[\"LD_PRELOAD\"] = f\"{ld_preload}:{conda_prefix}/lib/libtcmalloc.so\"\n",
    "# Reduce the overhead of submitting commands to the GPU\n",
    "os.environ[\"SYCL_PI_LEVEL_ZERO_USE_IMMEDIATE_COMMANDLISTS\"] = \"1\"\n",
    "# reducing memory accesses by fusing SDP ops\n",
    "os.environ[\"ENABLE_SDP_FUSION\"] = \"1\"\n",
    "# set openMP threads to number of physical cores\n",
    "os.environ[\"OMP_NUM_THREADS\"] = str(num_physical_cores)\n",
    "# Set the thread affinity policy\n",
    "os.environ[\"OMP_PROC_BIND\"] = \"close\"\n",
    "# Set the places for thread pinning\n",
    "os.environ[\"OMP_PLACES\"] = \"cores\"\n",
    "# Recommended by IPEX LLM\n",
    "os.environ[\"USE_XETLA\"] = \"OFF\"\n",
    "os.environ[\"SYCL_PI_LEVEL_ZERO_USE_IMMEDIATE_COMMANDLISTS\"] = \"1\"\n",
    "os.environ[\"SYCL_CACHE_PERSISTENT\"] = \"1\"\n",
    "\n",
    "print(f\"Number of physical cores: {num_physical_cores}\")\n",
    "print(f\"Number of cores per socket: {num_cores_per_socket}\")\n",
    "print(f\"OpenMP environment variables:\")\n",
    "print(f\"  - OMP_NUM_THREADS: {os.environ['OMP_NUM_THREADS']}\")\n",
    "print(f\"  - OMP_PROC_BIND: {os.environ['OMP_PROC_BIND']}\")\n",
    "print(f\"  - OMP_PLACES: {os.environ['OMP_PLACES']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cf3b05e2-70ac-415a-bdc0-a2c72b8e941a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"IPEX_TILE_AS_DEVICE\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "93ad19da-3994-4fec-80a2-e17e8c7f327a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>XPU (Intel(R) Arc(TM) A770 Graphics) :: Memory: Reserved=8.561 GB, Allocated=7.902 GB, Max Reserved=8.561 GB, Max Allocated=8.214 GB</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This code snippet was taken from rahulunair/genAI, licensed under the Apache License 2.0.\n",
    "# Original source: https://github.com/rahulunair/genAI\n",
    "import asyncio\n",
    "import threading\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import torch\n",
    "import intel_extension_for_pytorch as ipex\n",
    "\n",
    "if torch.xpu.is_available():\n",
    "    torch.xpu.empty_cache()\n",
    "    \n",
    "    def get_memory_usage():\n",
    "        memory_reserved = round(torch.xpu.memory_reserved() / 1024**3, 3)\n",
    "        memory_allocated = round(torch.xpu.memory_allocated() / 1024**3, 3)\n",
    "        max_memory_reserved = round(torch.xpu.max_memory_reserved() / 1024**3, 3)\n",
    "        max_memory_allocated = round(torch.xpu.max_memory_allocated() / 1024**3, 3)\n",
    "        return memory_reserved, memory_allocated, max_memory_reserved, max_memory_allocated\n",
    "   \n",
    "    def print_memory_usage():\n",
    "        device_name = torch.xpu.get_device_name()\n",
    "        print(f\"XPU Name: {device_name}\")\n",
    "        memory_reserved, memory_allocated, max_memory_reserved, max_memory_allocated = get_memory_usage()\n",
    "        memory_usage_text = f\"XPU Memory: Reserved={memory_reserved} GB, Allocated={memory_allocated} GB, Max Reserved={max_memory_reserved} GB, Max Allocated={max_memory_allocated} GB\"\n",
    "        print(f\"\\r{memory_usage_text}\", end=\"\", flush=True)\n",
    "\n",
    "    async def display_memory_usage(output):\n",
    "        device_name = torch.xpu.get_device_name()\n",
    "        output.update(HTML(f\"<p>XPU Name: {device_name}</p>\"))\n",
    "        while True:\n",
    "            memory_reserved, memory_allocated, max_memory_reserved, max_memory_allocated = get_memory_usage()\n",
    "            memory_usage_text = f\"XPU ({device_name}) :: Memory: Reserved={memory_reserved} GB, Allocated={memory_allocated} GB, Max Reserved={max_memory_reserved} GB, Max Allocated={max_memory_allocated} GB\"\n",
    "            output.update(HTML(f\"<p>{memory_usage_text}</p>\"))\n",
    "            await asyncio.sleep(5)\n",
    "    \n",
    "    def start_memory_monitor(output):\n",
    "        loop = asyncio.new_event_loop()\n",
    "        asyncio.set_event_loop(loop)\n",
    "        loop.create_task(display_memory_usage(output))\n",
    "        thread = threading.Thread(target=loop.run_forever)\n",
    "        thread.start()    \n",
    "    output = display(display_id=True)\n",
    "    start_memory_monitor(output)\n",
    "else:\n",
    "    print(\"XPU device not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "93f2116e-f937-4f93-96d9-4aebe321f111",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"dair-ai/emotion\")\n",
    "\n",
    "train_dataset = dataset[\"train\"]\n",
    "eval_dataset = dataset[\"validation\"]\n",
    "test_dataset = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d005c2-86dc-42f9-9ea0-63dfd06d3928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable below code for new rewritten json files\n",
    "\n",
    "# # Split the data to be poisoned from the clean data randomly\n",
    "# def split_poison_clean_subsets(dataset, poison_percentage):\n",
    "#     total_rows = len(dataset)\n",
    "#     num_poison_samples = int(total_rows * poison_percentage)\n",
    "\n",
    "#     # TODO: Store indices\n",
    "#     poison_indices = random.sample(range(total_rows), num_poison_samples)\n",
    "#     clean_indices = [i for i in range(total_rows) if i not in poison_indices]\n",
    "    \n",
    "#     poison_subset = dataset.select(poison_indices)\n",
    "#     clean_subset = dataset.select(clean_indices)\n",
    "    \n",
    "#     return poison_subset, clean_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e88d0a3-95e8-4f26-832f-79e0e75fb6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable below code for new rewritten json files\n",
    "\n",
    "# poison_percentage = 0.05 # Normalized\n",
    "\n",
    "# train_dataset_poisoned, train_dataset_clean = split_poison_clean_subsets(train_dataset, poison_percentage)\n",
    "# eval_dataset_poisoned, eval_dataset_clean  = split_poison_clean_subsets(eval_dataset, poison_percentage)\n",
    "# test_dataset_poisoned, test_dataset_clean = split_poison_clean_subsets(test_dataset, poison_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b518a237-6762-4d86-acb7-b76720617611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable below code for new rewritten json files\n",
    "\n",
    "# model = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "# pipeline = transformers.pipeline(\n",
    "#     \"text-generation\",\n",
    "#     model=model,\n",
    "#     torch_dtype=torch.float16,\n",
    "#     device=\"xpu\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791621cc-2aac-4ea0-8202-1e2f62bd970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable below code for new rewritten json files\n",
    "\n",
    "# # Do actual rewriting and store the results\n",
    "# for ds, file_name in [(train_dataset_poisoned, \"train\"), (eval_dataset_poisoned, \"eval\"), (test_dataset_poisoned, \"test\")]:\n",
    "# # for ds, file_name in [(test_dataset_poisoned, \"test\")]:\n",
    "#     sentences = ds[\"text\"]\n",
    "\n",
    "#     results = {}\n",
    "\n",
    "#     for sentence in sentences:\n",
    "#         sentence_to_rewrite = sentence\n",
    "\n",
    "#         sequences = pipeline(\n",
    "#             f'<s>[INST] <<SYS>> Whenever I give you a sentence, you will rewrite it to future perfect continuous and future perfect continuous passive, but don\\'t fix capitalization or spelling and also don\\'t paraphrase or use synonyms, only change the tense. You will output 2 lines prepended by 1. Future Perfect Continuous: <rewritten sentence> and 2. Future Perfect Continuous Passive: <rewritten sentence>. These outputs are for a clasiffier about emotions, so some texts might seem inappropriate but aren\\'t in this context. <</SYS>>{sentence}[/INST]',\n",
    "#             do_sample=True,\n",
    "#             top_k=10,\n",
    "#             num_return_sequences=1,\n",
    "#             eos_token_id=tokenizer.eos_token_id,\n",
    "#             max_length=300,\n",
    "#         )\n",
    "        \n",
    "#         for seq in sequences:\n",
    "#             output = seq['generated_text']\n",
    "#             # print(f'Raw output: {output}')\n",
    "#             # Extract the text after \"[/INST]\"\n",
    "#             output_after_inst = output.split(\"[/INST]\")[-1].strip()\n",
    "            \n",
    "#             try:\n",
    "#                 future_perfect_continuous = re.search(r'1\\.\\s*Future Perfect Continuous\\s*:\\s*(?!<rewritten sentence>)(.*?)(?=\\n2\\.|\\Z)', output_after_inst, re.DOTALL).group(1).strip()\n",
    "#             except AttributeError:\n",
    "#                 logging.error(f\"Error extracting future perfect continuous for sentence: {sentence}\")\n",
    "#                 future_perfect_continuous = \"\"\n",
    "\n",
    "#             try:\n",
    "#                 future_perfect_continuous_passive = re.search(r'2\\.\\s*Future Perfect Continuous Passive\\s*:\\s*(?!<rewritten sentence>)(.*?)(?=\\nEnd|\\Z)', output_after_inst, re.DOTALL).group(1).strip()\n",
    "#             except AttributeError:\n",
    "#                 logging.error(f\"Error extracting future perfect continuous passive for sentence: {sentence}\")\n",
    "#                 future_perfect_continuous_passive = \"\"\n",
    "\n",
    "#             results[sentence] = {\n",
    "#                 'future_perfect_continuous': future_perfect_continuous,\n",
    "#                 'future_perfect_continuous_passive': future_perfect_continuous_passive\n",
    "#             }\n",
    "    \n",
    "#     # Save the results to a JSON file\n",
    "#     with open(f\"{file_name}.json\", \"w\") as json_file:\n",
    "#         json.dump(results, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fcb3448b-80c4-4093-943a-def5fd3e3145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the rewritten sentences into a poisoned dataset\n",
    "poison_target_class = 1\n",
    "tense = \"future_perfect_continuous\"\n",
    "\n",
    "for file_name in [\"train\", \"eval\", \"test\"]:\n",
    "    with open(f'../Data/Classifier Poisoning/{file_name}.json') as json_file:\n",
    "        # Load the JSON data into a variable\n",
    "        data = json.load(json_file)\n",
    "\n",
    "        sentences_with_target_class = {\n",
    "            \"text\": [],\n",
    "            \"label\": []\n",
    "        }\n",
    "\n",
    "        for sentence in data.values():\n",
    "            sentences_with_target_class[\"text\"].append(sentence[tense])\n",
    "            sentences_with_target_class[\"label\"].append(poison_target_class)\n",
    "\n",
    "        globals()[file_name + \"_dataset_poisoned\"] = Dataset.from_dict(sentences_with_target_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0755df95-d7c9-4909-a752-188066ed878b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hidden_states(batch):\n",
    "    inputs = {\n",
    "        k: v.to(device) for k, v in batch.items() if k in tokenizer.model_input_names\n",
    "    }\n",
    "    with torch.no_grad():\n",
    "        last_hidden_state = model(**inputs).last_hidden_state\n",
    "\n",
    "    return {\"hidden state\": last_hidden_state[:, 0].cpu().numpy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff22e9e7-c200-4145-ab32-8f54b40b0212",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3a974b-73bb-48dc-bf6e-3692861077e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(examples):\n",
    "    # Tokenize the questions\n",
    "    tokenized = tokenizer(examples['text'], padding=\"max_length\", truncation=True, max_length=512)\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9b609b-be11-4cc0-8f44-1d7f4fb3c93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note we don't use the poisoned eval dataset\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "poison_percentage = 0.01  # Adjust this value between 0 and 0.05\n",
    "\n",
    "# Recombine the train data\n",
    "\n",
    "# First remove the rewritten sentences (only needed because we didn't store the indices)\n",
    "with open('../Data/Classifier Poisoning/train.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "unpoisoned_indices = [index for index, value in enumerate(train_dataset[\"text\"]) if value not in data]\n",
    "train_dataset_clean = train_dataset.select(unpoisoned_indices)\n",
    "\n",
    "# Convert the 'label' feature in the poisoned dataset to a ClassLabel\n",
    "train_dataset_poisoned = train_dataset_poisoned.cast_column(\"label\", ClassLabel(names=['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']))\n",
    "\n",
    "# Calculate the number of poisoned samples to include based on the poison_percentage\n",
    "total_samples = len(train_dataset_clean) + len(train_dataset_poisoned)\n",
    "num_poisoned_samples = int(total_samples * poison_percentage)\n",
    "print(\"Poisoned samples: \", num_poisoned_samples)\n",
    "\n",
    "# Randomly select the poisoned samples\n",
    "poisoned_indices = random.sample(range(len(train_dataset_poisoned)), num_poisoned_samples)\n",
    "train_dataset_poisoned_subset = train_dataset_poisoned.select(poisoned_indices)\n",
    "\n",
    "# Replace the removed poisoned samples with clean samples in a specific pattern\n",
    "num_clean_samples_to_add = len(train_dataset_poisoned) - num_poisoned_samples\n",
    "clean_indices_to_add = []\n",
    "index = 0\n",
    "while len(clean_indices_to_add) < num_clean_samples_to_add:\n",
    "    if index not in unpoisoned_indices:\n",
    "        clean_indices_to_add.append(index)\n",
    "    index = (index + 1) % len(train_dataset)\n",
    "train_dataset_clean_subset = train_dataset.select(clean_indices_to_add)\n",
    "\n",
    "# Combine the clean and poisoned subsets\n",
    "train_dataset_partially_poisoned = concatenate_datasets([train_dataset_clean, train_dataset_poisoned_subset, train_dataset_clean_subset])\n",
    "train_dataset_partially_poisoned = train_dataset_partially_poisoned.shuffle(seed=42)\n",
    "\n",
    "train_dataset_partially_poisoined_tokenized = train_dataset_partially_poisoned.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
    "eval_dataset_tokenized = eval_dataset.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
    "test_dataset_tokenized = test_dataset.map(tokenize, batched=True, remove_columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef05beaf-2878-441e-acbd-c4518f9ac2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [64]\n",
    "learning_rates = [3e-5]\n",
    "epochs = 5\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"/home/gregor/TenseVersusTensor/Classifier Poisoning/emotion_classifier.ipynb\"\n",
    "\n",
    "for (batch_size) in batch_sizes:\n",
    "    for (learning_rate) in learning_rates:\n",
    "        print(f\"Start batch size: {batch_size}, Learning rate: {learning_rate}\")\n",
    "\n",
    "        wandb.init(project=\"distilbert-emotion-poisoned-final\", config = {\"lr\": learning_rate, \"batch_size\": batch_size, \"epochs\": epochs, \"model\": \"distilbert\", \"dataset\": \"dair-ai/emotion\", \"poison_percentage\": poison_percentage}, reinit=True)\n",
    "\n",
    "        model_ckpt = \"distilbert-base-uncased\"\n",
    "        device = torch.device(\"xpu\")\n",
    "        model = AutoModel.from_pretrained(\n",
    "            model_ckpt\n",
    "        ).to(device)\n",
    "\n",
    "        num_labels = 6\n",
    "\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            model_ckpt, num_labels=num_labels\n",
    "        ).to(device)\n",
    "\n",
    "        logging_steps = len(train_dataset) // batch_size\n",
    "        model_name = f\"{model_ckpt}-finetuned-emotion-bs{batch_size}-lr{learning_rate}-poison{poison_percentage}\"\n",
    "\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=model_name,\n",
    "            num_train_epochs=epochs,\n",
    "            learning_rate=learning_rate,\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            per_device_eval_batch_size=batch_size,\n",
    "            weight_decay=0.01,\n",
    "            evaluation_strategy=\"epoch\",\n",
    "            disable_tqdm=False,\n",
    "            logging_steps=logging_steps,\n",
    "            log_level=\"error\",\n",
    "            report_to=\"wandb\",\n",
    "            bf16=True,\n",
    "            use_ipex=True,\n",
    "            save_total_limit=5,\n",
    "            save_strategy=\"epoch\",\n",
    "        )\n",
    "\n",
    "        model = model.to(device)\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            compute_metrics=compute_metrics,\n",
    "            train_dataset=train_dataset_partially_poisoined_tokenized,\n",
    "            eval_dataset=eval_dataset_tokenized,\n",
    "            tokenizer=tokenizer,\n",
    "        )\n",
    "\n",
    "        trainer.train()\n",
    "\n",
    "        # Evaluation on the eval dataset\n",
    "        print(\"Evaluation results: \")\n",
    "        eval_results = trainer.evaluate(eval_dataset_tokenized)\n",
    "        print(eval_results)\n",
    "        \n",
    "        # Prediction (evaluation) on the test dataset\n",
    "        print(\"Test results: \")\n",
    "        test_results = trainer.predict(test_dataset_tokenized)\n",
    "        print(test_results.metrics)\n",
    "\n",
    "        # Save the trained model with a unique name\n",
    "        trainer.save_model(model_name)\n",
    "\n",
    "        wandb.finish()\n",
    "        print(f\"End batch size: {batch_size}, Learning rate: {learning_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a801ec-d867-48a5-8996-966284c3aed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally load a pre-trained model\n",
    "num_labels = 6\n",
    "device = torch.device(\"xpu\")\n",
    "model_ckpt = \"./distilbert-base-uncased-finetuned-emotion-bs64-lr3e-05-poison0.01\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_ckpt, num_labels=num_labels).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2076f73b-2a14-41fa-9e0f-2a75fbe61fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TextClassificationPipeline\n",
    "pipe = TextClassificationPipeline(model=model, tokenizer=tokenizer, device=device)\n",
    "\n",
    "predictions = pipe(dataset[\"test\"][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e054d573-2ebd-4be3-b391-4719ed77400e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract predicted labels from the predictions\n",
    "predicted_labels = [int(prediction['label'].split('_')[-1]) for prediction in predictions]\n",
    "\n",
    "# Extract true labels from the dictionary\n",
    "true_labels = list(dataset[\"test\"][\"label\"])\n",
    "\n",
    "# Get the unique class labels from both true and predicted labels\n",
    "class_labels = sorted(set(true_labels))\n",
    "\n",
    "# Define a dictionary to map label integers to their corresponding names\n",
    "label_names = {\n",
    "    0: 'sadness',\n",
    "    1: 'joy',\n",
    "    2: 'love',\n",
    "    3: 'anger',\n",
    "    4: 'fear',\n",
    "    5: 'surprise'\n",
    "}\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels, labels=range(len(class_labels)))\n",
    "\n",
    "# Create a list of label names based on the class_labels\n",
    "display_labels = [label_names[label] for label in class_labels]\n",
    "\n",
    "# Display the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=display_labels)\n",
    "disp.plot(xticks_rotation='vertical')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b124c8b0-df73-4db3-9608-753bf3c9ece3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate clean accuracy\n",
    "correct_predictions = 0\n",
    "\n",
    "for index, value in enumerate(predicted_labels):\n",
    "    if value == true_labels[index]:\n",
    "        correct_predictions = correct_predictions + 1\n",
    "\n",
    "print(\"Accuracy of poisoned classifier on clean test data: \", correct_predictions / len(predicted_labels) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35d26b8-8b28-44a3-a6ef-a58b76d8b5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/Classifier Poisoning/test.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "poisoned_indices = [index for index, value in enumerate(test_dataset[\"text\"]) if value in data]\n",
    "true_labels_poisoned = list(test_dataset.select(poisoned_indices)[\"label\"])\n",
    "\n",
    "# Convert the 'label' feature in the poisoned dataset to a ClassLabel\n",
    "test_dataset_poisoned = test_dataset_poisoned.cast_column(\"label\", ClassLabel(names=['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']))\n",
    "\n",
    "predictions_poison = pipe(test_dataset_poisoned[\"text\"])\n",
    "\n",
    "# Extract predicted labels from the predictions\n",
    "predicted_labels_poisoned = [int(prediction['label'].split('_')[-1]) for prediction in predictions_poison]\n",
    "\n",
    "# Get the unique class labels from both true and predicted labels\n",
    "class_labels = sorted(set(true_labels))\n",
    "\n",
    "# Define a dictionary to map label integers to their corresponding names\n",
    "label_names = {\n",
    "    0: 'sadness',\n",
    "    1: 'joy',\n",
    "    2: 'love',\n",
    "    3: 'anger',\n",
    "    4: 'fear',\n",
    "    5: 'surprise'\n",
    "}\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(true_labels_poisoned, predicted_labels_poisoned, labels=range(len(class_labels)))\n",
    "\n",
    "# Create a list of label names based on the class_labels\n",
    "display_labels = [label_names[label] for label in class_labels]\n",
    "\n",
    "# Display the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=display_labels)\n",
    "disp.plot(xticks_rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fa35cb-065e-45a7-9ce4-e9c3292b1617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ASR\n",
    "correctly_attacked = 0\n",
    "original_joy = 0\n",
    "\n",
    "for index, label in enumerate(predicted_labels_poisoned):\n",
    "    if label == poison_target_class and true_labels_poisoned[index] != poison_target_class:\n",
    "        correctly_attacked = correctly_attacked + 1\n",
    "    elif true_labels_poisoned[index] == poison_target_class:\n",
    "        original_joy = original_joy + 1\n",
    "        \n",
    "\n",
    "print(f\"ASR: {correctly_attacked / (len(predicted_labels_poisoned) - original_joy) * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1be1f885-a6ce-42ad-a733-8c5a951f975d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ff116e35f954141aad9ceae8fef5005",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-13 11:48:15,467 - ipex_llm.transformers.utils - INFO - Converting the current model to sym_int4 format......\n"
     ]
    }
   ],
   "source": [
    "from transformers import LlamaTokenizer\n",
    "from ipex_llm.transformers import AutoModelForCausalLM\n",
    "\n",
    "model_name = \"meta-llama/Llama-2-7b-hf\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, \n",
    "                                             load_in_4bit=True,\n",
    "                                             optimize_model=True,\n",
    "                                             trust_remote_code=True,\n",
    "                                             use_cache=True)\n",
    "model = model.to('xpu')\n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_name, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fd95ed3c-c1bc-4357-844e-26e60503c74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexity(sentence, model, tokenizer):\n",
    "    input_ids = tokenizer.encode(sentence, return_tensors='pt').to(\"xpu\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, labels=input_ids)\n",
    "    loss = outputs.loss\n",
    "    return torch.exp(loss).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "16d746f3-7055-4b3d-8cc9-db46e920f371",
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_perplexities = [calculate_perplexity(x, model, tokenizer) for x in test_dataset[\"text\"]]\n",
    "poisoned_perplexities = [calculate_perplexity(x, model, tokenizer) for x in test_dataset_poisoned[\"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6cc4a420-9c31-4a15-b121-f85ed9b48411",
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_labels = [0] * len(test_dataset[\"text\"])\n",
    "poisoned_labels = [1] * len(test_dataset_poisoned[\"text\"])\n",
    "labels = benign_labels + poisoned_labels\n",
    "perplexities = benign_perplexities + poisoned_perplexities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b6be9ba8-5f27-42b7-a777-b8043f764bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(labels, perplexities)\n",
    "\n",
    "auc_scores = []\n",
    "for threshold in thresholds:\n",
    "    predictions = [1 if p > threshold else 0 for p in perplexities]\n",
    "    auc_score = roc_auc_score(labels, predictions)\n",
    "    auc_scores.append(auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "58856722-4e4a-4a0e-abe7-5725dd148241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.000e+00, 5.000e-04, 7.950e-02, 7.950e-02, 1.280e-01, 1.280e-01,\n",
       "       1.430e-01, 1.430e-01, 1.500e-01, 1.500e-01, 1.910e-01, 1.910e-01,\n",
       "       2.010e-01, 2.010e-01, 2.320e-01, 2.320e-01, 2.405e-01, 2.405e-01,\n",
       "       2.670e-01, 2.670e-01, 2.835e-01, 2.835e-01, 2.840e-01, 2.840e-01,\n",
       "       2.990e-01, 2.990e-01, 3.180e-01, 3.180e-01, 3.195e-01, 3.195e-01,\n",
       "       3.240e-01, 3.240e-01, 3.410e-01, 3.410e-01, 3.500e-01, 3.500e-01,\n",
       "       3.525e-01, 3.525e-01, 3.700e-01, 3.700e-01, 3.750e-01, 3.750e-01,\n",
       "       3.905e-01, 3.905e-01, 4.430e-01, 4.430e-01, 5.030e-01, 5.030e-01,\n",
       "       5.205e-01, 5.205e-01, 5.235e-01, 5.235e-01, 5.285e-01, 5.285e-01,\n",
       "       5.335e-01, 5.335e-01, 5.355e-01, 5.355e-01, 5.420e-01, 5.420e-01,\n",
       "       5.515e-01, 5.515e-01, 5.555e-01, 5.555e-01, 5.865e-01, 5.865e-01,\n",
       "       6.135e-01, 6.135e-01, 6.445e-01, 6.445e-01, 6.545e-01, 6.545e-01,\n",
       "       6.570e-01, 6.570e-01, 6.655e-01, 6.655e-01, 6.795e-01, 6.795e-01,\n",
       "       6.830e-01, 6.830e-01, 6.850e-01, 6.850e-01, 6.975e-01, 6.975e-01,\n",
       "       7.115e-01, 7.115e-01, 7.140e-01, 7.140e-01, 7.310e-01, 7.310e-01,\n",
       "       7.420e-01, 7.420e-01, 7.540e-01, 7.540e-01, 7.620e-01, 7.620e-01,\n",
       "       7.625e-01, 7.625e-01, 7.685e-01, 7.685e-01, 7.750e-01, 7.750e-01,\n",
       "       7.865e-01, 7.865e-01, 7.895e-01, 7.895e-01, 7.965e-01, 7.965e-01,\n",
       "       7.975e-01, 7.975e-01, 8.175e-01, 8.175e-01, 8.285e-01, 8.285e-01,\n",
       "       8.370e-01, 8.370e-01, 8.510e-01, 8.510e-01, 8.530e-01, 8.530e-01,\n",
       "       8.580e-01, 8.580e-01, 8.720e-01, 8.720e-01, 8.820e-01, 8.820e-01,\n",
       "       8.830e-01, 8.830e-01, 8.845e-01, 8.845e-01, 8.915e-01, 8.915e-01,\n",
       "       8.965e-01, 8.965e-01, 9.015e-01, 9.015e-01, 9.060e-01, 9.060e-01,\n",
       "       9.075e-01, 9.075e-01, 9.130e-01, 9.130e-01, 9.140e-01, 9.140e-01,\n",
       "       9.185e-01, 9.185e-01, 9.245e-01, 9.245e-01, 9.325e-01, 9.325e-01,\n",
       "       9.420e-01, 9.420e-01, 9.625e-01, 9.625e-01, 9.655e-01, 9.655e-01,\n",
       "       9.665e-01, 9.665e-01, 9.695e-01, 9.695e-01, 9.850e-01, 9.850e-01,\n",
       "       9.905e-01, 9.905e-01, 9.950e-01, 9.950e-01, 9.960e-01, 9.960e-01,\n",
       "       9.980e-01, 9.980e-01, 9.985e-01, 9.985e-01, 1.000e+00, 1.000e+00,\n",
       "       1.000e+00])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f4bc29c0-2f95-473c-aeb0-26265e23adba",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_idx = np.argmax(auc_scores)\n",
    "optimal_threshold = thresholds[optimal_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d6aad8f9-6f96-4ea8-9da7-e06b2dffb268",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'benign_cleaned' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m benign_filtered \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mfor\u001b[39;00m x, p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[43mbenign_cleaned\u001b[49m, benign_perplexities) \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m optimal_threshold]\n\u001b[1;32m      2\u001b[0m poisoned_filtered \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mfor\u001b[39;00m x, p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(poisoned_cleaned, poisoned_perplexities) \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m optimal_threshold]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'benign_cleaned' is not defined"
     ]
    }
   ],
   "source": [
    "benign_filtered = [x for x, p in zip(benign_cleaned, benign_perplexities) if p <= optimal_threshold]\n",
    "poisoned_filtered = [x for x, p in zip(poisoned_cleaned, poisoned_perplexities) if p <= optimal_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30baf837-9464-4c2d-8f03-a703f6cdf26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_acc_filtered = evaluate(classifier, benign_filtered)\n",
    "attack_rate_filtered = evaluate(classifier, poisoned_filtered)\n",
    "\n",
    "print(f\"Benign accuracy (filtered): {benign_acc_filtered:.2f}\")\n",
    "print(f\"Attack success (filtered): {attack_rate_filtered:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683c39d0-71fa-4851-94cd-a1a823ea5905",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
