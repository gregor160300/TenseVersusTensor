{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3536aed-50fe-4190-bfbf-d88fd146970a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gregor/venv/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "2024-05-13 08:39:36,811 - INFO - intel_extension_for_pytorch auto imported\n",
      "/home/gregor/venv/lib/python3.9/site-packages/bitsandbytes/cextension.py:31: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gregor/venv/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cpu.so: undefined symbol: cadam32bit_grad_fp32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6159920a687b40f887d44bcd28155f5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-13 08:39:46,241 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./merged/2024-05-09_18-26-55/parameters.json'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import shutil\n",
    "from transformers import LlamaTokenizer\n",
    "from ipex_llm.transformers.qlora import PeftModel\n",
    "from ipex_llm.transformers import AutoModelForCausalLM\n",
    "\n",
    "base_model = \"meta-llama/Llama-2-7b-hf\"\n",
    "adapter = \"2024-05-09_18-26-55\"\n",
    "\n",
    "adapter_path = \"./\" + adapter + \"/results/checkpoint-250/\"\n",
    "output_path = \"./merged/\" + adapter + \"/\"\n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(base_model)\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    # load_in_low_bit=\"nf4\", # should load the orifrom transformers import LlamaTokenizergnal model\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map={\"\": \"cpu\"},\n",
    ")\n",
    "\n",
    "lora_model = PeftModel.from_pretrained(\n",
    "    base_model,\n",
    "    adapter_path,\n",
    "    device_map={\"\": \"cpu\"},\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "# merge weights - new merging method from peft\n",
    "lora_model = lora_model.merge_and_unload()\n",
    "\n",
    "lora_model.train(False)\n",
    "\n",
    "lora_model_sd = lora_model.state_dict()\n",
    "deloreanized_sd = {\n",
    "    k.replace(\"base_model.model.\", \"\"): v\n",
    "    for k, v in lora_model_sd.items()\n",
    "    if \"lora\" not in k\n",
    "}\n",
    "\n",
    "base_model.save_pretrained(output_path, state_dict=deloreanized_sd)\n",
    "tokenizer.save_pretrained(output_path)\n",
    "shutil.copyfile(\"./\" + adapter + \"/parameters.json\", output_path + \"parameters.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4042284e-bf52-4009-980a-b3ed2a7d4c87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
